{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "LOAD_FROM_PICKLE = False\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {‘0’, ‘1’, ‘2’}\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '0'\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n",
    "\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kernel needs to be restarted before changing this setting to take effect\n",
    "\n",
    "if USE_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow import needs to be after setting the CUDA_VISIBLE_DEVICES\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (GRU, LSTM, Activation, Conv1D, Dense,\n",
    "                                     Dropout, Embedding, Flatten, Input,\n",
    "                                     InputLayer, MaxPooling1D, concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# print Tensorflow and CUDA information\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    name = details.get('device_name', 'Unknown GPU')\n",
    "    \n",
    "    print(f\"Using {name}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored in the folowing way:\n",
    "# \"rating\", \"title\", \"review\" all as strings\n",
    "# \"1\" is negative, \"2\" is positive\n",
    "\n",
    "if LOAD_FROM_PICKLE:\n",
    "    with open('../Data/Pickle/reviews.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    print('Loaded data from pickle')\n",
    "else:\n",
    "    data = pd.read_csv('../Data/Amazon_Reviews/reviews.csv', names=['rating', 'title', 'review'], low_memory=False, header=0)\n",
    "\n",
    "    # combine title and review\n",
    "    data['review'] = data['title'] + ' ' + data['review']\n",
    "\n",
    "    # remove title\n",
    "    data.drop('title', axis=1, inplace=True)\n",
    "\n",
    "    # turn sets of spaces into single space\n",
    "    data['review'] = data['review'].str.replace(' +', ' ')\n",
    "\n",
    "    # remove leading and trailing spaces\n",
    "    data['review'] = data['review'].str.strip()\n",
    "\n",
    "    # convert rating to uint8\n",
    "    data['rating'] = data['rating'].astype('uint8')\n",
    "\n",
    "    # convert rating to 0 and 1 where 0 is positive and 1 is negative\n",
    "    data['rating'] = data['rating'].apply(lambda x: 0 if x == 2 else 1)\n",
    "\n",
    "    # save as pickle\n",
    "    with open('../Data/Pickle/reviews.pickle', 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print('Loaded data from csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Rating: {data['rating'][i]}\")\n",
    "    print(f\"Review: {data['review'][i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some statistics\n",
    "print(f\"Number of reviews: {len(data):,}\")\n",
    "print(f\"Number of positive reviews: {len(data[data['rating'] == 1]):,}\")\n",
    "print(f\"Number of negative reviews: {len(data[data['rating'] == 0]):,}\")\n",
    "\n",
    "review_lengths = [len(review.split()) for review in data['review'].astype(str)]\n",
    "\n",
    "# print the longest review in words\n",
    "print(f\"Longest review in words: {max(review_lengths)}\")\n",
    "\n",
    "# print the 99th percentile of review lengths\n",
    "print(f\"99th percentile of review lengths: {np.percentile(review_lengths, 99)}\")\n",
    "\n",
    "# graph the number of words in each review\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "sns.histplot(review_lengths, bins=100, kde=True)\n",
    "\n",
    "plt.title('Review length distribution')\n",
    "plt.xlabel('Number of words')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.xlim(0, 257)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['review'].astype(str).values\n",
    "y = data['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOP_WORDS = None # use entire vocabulary!\n",
    "MAX_ART_LEN = 200 # maximum and minimum number of words\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "if LOAD_FROM_PICKLE:\n",
    "    with open('../Data/Pickle/reviews_tokenized.pickle', 'rb') as handle:\n",
    "        X, word_index = pickle.load(handle)\n",
    "        NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "        top_words = min((len(word_index), NUM_TOP_WORDS))\n",
    "\n",
    "    print('Loaded tokenized X from pickle')\n",
    "else:\n",
    "    tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "    top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "\n",
    "    X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "\n",
    "    # save as pickle\n",
    "    with open('../Data/Pickle/reviews_tokenized.pickle', 'wb') as handle:\n",
    "        pickle.dump((X, word_index), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "print(f\"Found {len(word_index):,} unique tokens. Distilled to {top_words:,} top words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('../Data/GloVe/glove.6B.100d.txt')\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(f\"Found {len(embeddings_index):,} word vectors.\\n\")\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(f\"Embedding Shape: {embedding_matrix.shape}\")\n",
    "print(f\"Total words found: {found_words:,}\")\n",
    "print(f\"Percentage: {round(100 * found_words / embedding_matrix.shape[0], 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X, y_ohe, test_size=0.2, stratify=y)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train_ohe shape: {y_train_ohe.shape}\")\n",
    "print(f\"y_test_ohe shape: {y_test_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these three functions are from https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)\n",
    "\n",
    "def create_RNN(name, RNN_layer_type, num_units):\n",
    "    if RNN_layer_type == 'LSTM':\n",
    "        RNN_layer = LSTM\n",
    "    elif RNN_layer_type == 'GRU':\n",
    "        RNN_layer = GRU\n",
    "    else:\n",
    "        raise ValueError(\"RNN_layer_type must be one of 'LSTM' or 'GRU'\")\n",
    "\n",
    "    rnn = Sequential(name=name)\n",
    "    rnn.add(embedding_layer)\n",
    "    rnn.add(RNN_layer(num_units, dropout=0.2))\n",
    "    rnn.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "    rnn.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', \n",
    "                metrics=['accuracy', recall_m])\n",
    "\n",
    "    return rnn\n",
    "\n",
    "rnn1 = create_RNN('RNN-LSTM-25', 'LSTM', 25)\n",
    "rnn2 = create_RNN('RNN-GRU-25', 'GRU', 25)\n",
    "rnn3 = create_RNN('RNN-LSTM-50', 'LSTM', 50)\n",
    "rnn4 = create_RNN('RNN-GRU-50', 'GRU', 50)\n",
    "\n",
    "models = [rnn1, rnn2, rnn3, rnn4]\n",
    "\n",
    "for model in models:\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_STORED_MODELS = False\n",
    "\n",
    "if LOAD_STORED_MODELS:\n",
    "    for model in models:\n",
    "        # load model\n",
    "        model.load_weights(f\"Models/Lab7/{model.name}.h5\")\n",
    "        #load history\n",
    "        with open(f\"Models/Lab7/{model.name}.pk1\", 'rb') as file_pi:\n",
    "            model.history = pickle.load(file_pi)\n",
    "else:\n",
    "    for model in models:\n",
    "        start = time.time()\n",
    "\n",
    "        history = model.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=25, batch_size=2048, verbose=1)\n",
    "\n",
    "        print(f\"Model {model.name} took {round(time.time() - start, 2)} seconds to train\")\n",
    "\n",
    "        # Save model\n",
    "        model.save_weights(f\"Models/Lab7/{model.name}.h5\")\n",
    "        # save history\n",
    "        with open(f\"Models/Lab7/{model.name}.pkl\", 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        print(f\"Model {model.name} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(histories):\n",
    "    combined = dict()\n",
    "    for key in ['accuracy','val_accuracy','loss','val_loss', 'recall_m', 'val_recall_m']:\n",
    "        combined[key] = np.hstack([x.history[key] for x in histories[0]])\n",
    "        \n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(combined['accuracy'])\n",
    "    plt.plot(combined['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(combined['loss'])\n",
    "    plt.plot(combined['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
